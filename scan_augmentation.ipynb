{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from monai.utils import first\n",
    "\n",
    "from monai.transforms import Compose, RandFlip, RandRotate, RandAdjustContrast, LoadImaged, Orientationd, RandSpatialCropd, ScaleIntensityRanged, Spacingd, Resized, ToTensord, ScaleIntensityd, RandRotated, Flipd, RandAffined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create function that takes in scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, patch_size=(64,64,64)):\n",
    "    \"\"\"\n",
    "    patch_size = tuple containing patch size of images for training\n",
    "\n",
    "    T1- native format \n",
    "    T1CE - contrast enhanced image of T1\n",
    "    T2 - weighted\n",
    "    T2 Fluid Attenuated Inversion Recovery FLAIR volumes\n",
    "    \"\"\"\n",
    "    t1ce_all = []\n",
    "    t1_all = []\n",
    "    t2_all = []\n",
    "    flair_all = []\n",
    "    mask_all = []\n",
    "\n",
    "    # search through MRI files and assign sample names to image files by labeling. \n",
    "    for mri_folder in os.listdir(path):\n",
    "        file_path = os.path.join(path, mri_folder)\n",
    "\n",
    "        #extracting t1ce for all 369 patients\n",
    "        t1ce_files = glob.glob(os.path.join(file_path, \"*_t1ce.nii\")) #returns a list\n",
    "        for t1ce_file in t1ce_files:\n",
    "            t1ce_img = nib.load(t1ce_file)\n",
    "            t1ce_img_data = t1ce_img.get_fdata()\n",
    "            t1ce_all.append(t1ce_img_data)\n",
    "        \n",
    "        #extracting t2-weighted for all 369 patients\n",
    "        t2_weighted_files = glob.glob(os.path.join(file_path, \"*_t2.nii\"))\n",
    "        for t2_weighted_file in t2_weighted_files:\n",
    "            t2_weighted_img = nib.load(t2_weighted_file)\n",
    "            t2_weighted_img_data = t2_weighted_img.get_fdata()\n",
    "            t2_all.append(t2_weighted_img_data)\n",
    "    \n",
    "        #extracting t2-flair data for all 369 patients       \n",
    "        t2_flair_files = glob.glob(os.path.join(file_path, \"*_flair.nii\")) #returns a list\n",
    "        for t2_flair_file in t2_flair_files:\n",
    "            t2_flair_img = nib.load(t2_flair_file)\n",
    "            t2_flair_img_data = t2_flair_img.get_fdata()\n",
    "            #height, width, depth = t2_flair_img_data.shape\n",
    "            #print(f'height = {height}, width = {width}, depth = {depth}')\n",
    "            flair_all.append(t2_flair_img_data)\n",
    "            \n",
    "        #extracting t1 data for all 369 patients\n",
    "        t1_files = glob.glob(os.path.join(file_path, \"*_t1.nii\"))\n",
    "        for t1_file in t1_files:\n",
    "            t1_img = nib.load(t1_file)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "            t1_all.append(t1_data)\n",
    "        \n",
    "        mask_files = glob.glob(os.path.join(file_path, \"*_seg.nii\"))\n",
    "        for mask_file in mask_files:\n",
    "            mask_file_img = nib.load(mask_file)\n",
    "            mask_file_img_data = mask_file_img.get_fdata()\n",
    "            mask_all.append(mask_file_img_data)\n",
    "\n",
    "    return mask_all,t1_all, t1ce_all, t2_all, flair_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_data, t1_data, t1ce_data, t2_data, flair_data = load_data('/Users/dolan/Dropbox/MSSE/277B_ML/277B_final/277B_final/BraTS2020_scans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scan augmentation\n",
    "\n",
    "we want to augment by doing both random rotations, random flips, and random contrast on the scans\n",
    "\n",
    "random rotations and flips simulate patients being in slightly different positions in the scanner\n",
    "\n",
    "random constrast simulates the fact that different scanners will have varying contrasts\n",
    "\n",
    "\n",
    "then save them as \n",
    "\n",
    "patient_n_augmented (folder) #note that there is no t1_aug\n",
    "\n",
    "-patient_n_t1ce_aug.nii\n",
    "\n",
    "-patient_n_t2_aug.nii\n",
    "\n",
    "-patient_n_flair_aug.nii\n",
    "\n",
    "-patient_n_mask_aug.nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monai augmentation \n",
    "\"\"\"\n",
    "generate_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged \n",
    "        AddChanneled\n",
    "        Spacingd\n",
    "        Orientationd\n",
    "        ScaleIntensityRanged\n",
    "        RandAffined\n",
    "        RandRotated\n",
    "        ToTensord\n",
    "\n",
    "    ]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "generate_transforms = Compose ([\n",
    "    RandFlip(spatial_axis = (0,1,2), prob = 0.5), \n",
    "    RandRotate(range_x = 10, range_y = 10, prob = 0.5),\n",
    "    RandAdjustContrast(prob = 0.5, gamma = (0.8,1.2))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.memmap'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def augment_data(images, masks, transforms):\n",
    "    \"\"\"\n",
    "    Apply augmentations to images and masks.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of loaded images (e.g., NumPy arrays).\n",
    "        masks (list): List of corresponding masks (e.g., NumPy arrays).\n",
    "        transforms (Compose): MONAI Compose object with augmentations.\n",
    "    \n",
    "    Returns:\n",
    "        list: Augmented images.\n",
    "        list: Augmented masks.\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    augmented_masks = []\n",
    "\n",
    "    for img, mask in zip(images, masks):\n",
    "        augmented = transforms({\"image\": img, \"label\": mask})\n",
    "        augmented_images.append(augmented[\"image\"])\n",
    "        augmented_masks.append(augmented[\"label\"])\n",
    "\n",
    "    return augmented_images, augmented_masks\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(t1ce,t2,flair,mask):\n",
    "    t1ce_aug_all = []\n",
    "    t2_aug_all = []\n",
    "    flair_aug_all = []\n",
    "    mask_aug_all = []\n",
    "\n",
    "    channel_dict = {\"t1ce\": t1ce, \"t2\": t2, \"flair\":flair, \"mask\":mask}\n",
    "    augmented = generate_transforms(channel_dict)\n",
    "\n",
    "    t1ce_aug_all.append(augmented[\"t1ce\"])\n",
    "    t2_aug_all.append(augmented[\"t2\"])\n",
    "    flair_aug_all.append(augmented[\"flair\"])\n",
    "    mask_aug_all.append(augmented[\"mask\"])\n",
    "\n",
    "    return t1ce_aug_all, t2_aug_all, flair_aug_all, mask_aug_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "t1ce_aug, t2_aug, flair_aug, mask_aug = augment_data(t1ce_data, t2_data, flair_data, mask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_generator(t1ce,t2,flair,mask, batch_size):\n",
    "    for i in range(0, len(t1ce), batch_size):\n",
    "        t1ce_batch = t1ce[i:i+ batch_size]\n",
    "        t2_batch = t2[i, i + batch_size]\n",
    "        flair_batch = flair[i , i + batch_size]\n",
    "        mask_batch = mask[i, i + batch_size]\n",
    "\n",
    "        yield t1ce_batch, t2_batch, flair_batch, mask_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1ce_aug = []\n",
    "t2_aug = []\n",
    "flair_aug = []\n",
    "mask_aug = []\n",
    "for t1ce_batch, t2_batch, flair_batch, mask_batch in augment_generator(t1ce_data, t2_data, flair_data, mask_data):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
